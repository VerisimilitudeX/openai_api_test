{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3 (ipykernel)",
            "language": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0,
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 1. Setting up"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Import all required modules"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.metrics import mean_squared_error\n",
                "from sklearn.linear_model import Ridge\n",
                "from sklearn.linear_model import Lasso\n",
                "from sklearn.linear_model import LinearRegression\n",
                "from sklearn.model_selection import cross_val_score\n",
                "\n",
                "np.random.seed(416)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Note:** Whenever you see print statements, you can uncomment them and run the code block to gain an understanding of the dataset.\n",
                "\n",
                "\n",
                "Read in the crime data of Philedelphia and view it. For additional info on the dataset we're using, see [this](https://www.kaggle.com/datasets/minnieliang/philadelphia-crime-rate-data).\n",
                "\n",
                "**Discussion:** Notice the shape of the data. Do you see anything that is a problem?\n",
                "\n",
                "Let's try to understand the dataset we are using. Each row represents the data of a particular city. the features are:\n",
                "\n",
                "1. HousePrice = the mean house price in that city\n",
                "2. HsPrc($10,000) = HousePrice / 10,000\n",
                "3. CrimeRate = Crime rate in that city\n",
                "4. MilesPhila = Miles of city from Philedelphia\n",
                "5. popChg = change in population \n",
                "6. Name = Name of the city\n",
                "7. County = County the city is in"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TODO: read in crime data and view"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 2. Pre-processing"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We want to predict the crime rate for a city in Philedelphia. **What input columns should we use?** (There are multiple reasonable answers.)\n",
                "\n",
                "We believe that the County names are also useful. But they are not numeric.\n",
                "\n",
                "**Discussion:** How do you think we can use those values? [Hint: Can we numerically encode them?]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "#One hot encoding all the county values\n",
                "one_hot = pd.get_dummies(crime['County'])\n",
                "#print(one_hot)\n",
                "\n",
                "#We then concatinate the one hot columns with original dataset.\n",
                "crime = pd.concat([crime, one_hot], axis=1)\n",
                "\n",
                "# We need to drop any and all NaN values to filter our data. So we drop any rows that contain a NaN \n",
                "crime = crime.dropna()\n",
                "print(crime)\n",
                "\n",
                "#Now, let's try to find relevant features in our dataset\n",
                "input_cols = [???]\n",
                "output_col = 'CrimeRate'"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Split the crime data into a training and test set and then store the input and target data seperately for each set. Use [train/test split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) from sklearn."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TODO: split into training and testing sets\n",
                "train, test = ???\n",
                "\n",
                "# TODO: split data sets into input and target variables\n",
                "train_X = ???\n",
                "train_y = ???\n",
                "\n",
                "test_X = ???\n",
                "test_y = ???"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Check the shape of each set to make sure they make sense!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"train input data shape:\", train_X.shape)\n",
                "print(\"train target data shape:\", train_y.shape)\n",
                "print()\n",
                "print(\"test input data shape:\", test_X.shape)\n",
                "print(\"test target data shape:\", test_y.shape)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Normalize training and test set input data (X) using statistics generated from the training set. To do this, use the [Standard Scaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) from sklearn. (**Conceptual Check**: Why is it important to use statistics generated from the training set?)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "scaler = StandardScaler()\n",
                "\n",
                "# TODO: Fit StandardScaler() with training data and apply to both training and test data"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "View the type of the data post-normalization (as well as the data itself)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"data type after normalizaton:\", type(train_X_norm))\n",
                "pd.DataFrame(train_X_norm)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 3. Regularization with Ridge"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Create a [Ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html) linear model with a regularization coefficent of 1. \n",
                "\n",
                "Note: This coefficent is referred to as \"lambda (Î»)\" in course material and \"alpha\" in the sklearn docs. They are the same thing!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TODO: construct Ridge regularization model with alpha=1.0\n",
                "ridge_model = ???"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Train the model using the training data and output the training error. To do so, define a function rmse(mode, X, y) that calculates the RMSE error for a given model, input, and target data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "def rmse(model, X, y):\n",
                "    predictions = model.predict(X)\n",
                "    return mean_squared_error(predictions, y, squared=False)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TODO: train Ridge model with training data and output train error using rmse()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Perform 5-fold cross validation with your Ridge model. Output the array of errors (length 5) as well as the mean error. You should use [Cross Validation Score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html?highlight=cross_val_scor) from sklearn to do this."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TODO: fill out parameters for cross_val_score() and print errors\n",
                "ridge_CV_scores = cross_val_score(???, ???, ???, cv=5, scoring=rmse)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Perform 5-fold cross validation on Ridge models with a range of alpha values. For each alpha, print the alpha value and the corresponding mean CV score."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "for reg_coef in [0.0001, 0.1, 1, 10, 100, 1000, 10e4, 10e7]:\n",
                "    ridge_model = Ridge(alpha=reg_coef)\n",
                "    ridge_CV_scores = cross_val_score(???, ???, ???, cv=5, scoring=rmse)\n",
                "    print(reg_coef, ridge_CV_scores.mean(), sep='\\t')"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Take a look at how the weights of Ridge models change as you change the regularization coefficient!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "ename": "NameError",
                    "evalue": "name 'input_cols' is not defined",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                        "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m\u003ccell line: 1\u003e\u001b[0;34m()\u001b[0m\n\u001b[0;32m----\u003e 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReg coeff. | \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIntercept | \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43minput_cols\u001b[49m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_________________________________________________\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m()\n",
                        "\u001b[0;31mNameError\u001b[0m: name 'input_cols' is not defined"
                    ]
                }
            ],
            "source": [
                "print(\"Reg coeff. | \", \"Intercept | \", input_cols)\n",
                "print(\"_________________________________________________\")\n",
                "\n",
                "for reg_coef in [0.0001, 0.1, 1, 10, 100, 1000, 10e4, 10e7]:\n",
                "    ridge_model = Ridge(alpha=reg_coef)\n",
                "    ridge_model.fit(train_X_norm, train_y)\n",
                "    print(reg_coef,\" | \", ridge_model.intercept_, \" | \", ridge_model.coef_)\n",
                "    print()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Concept check**: How would the weights be different if you didn't regularize them? (i.e., use `LinearRegression` instead of `Ridge`.)\n",
                ""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                ""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 4. Regularization with LASSO"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Create a [LASSO](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html) linear model with a regularization coefficent of 1."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TODO: construct LASSO regularization model with alpha=1.0\n",
                "lasso_model = ???"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Train the model using the training data and output the training error."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TODO: train LASSO model with training data and output train error using rmse()# TODO: train LASSO model with training data and output train error using rmse()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Perform 5-fold cross validation with your LASSO model. Output the array of errors (length 5) as well as the mean error."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TODO: fill out parameters for cross_val_score() and print errors\n",
                "lasso_CV_scores = cross_val_score(???, ???, ???, cv=5, scoring=rmse)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Perform 5-fold cross validation on LASSO models with a range of alpha values. For each alpha, print the alpha value and the corresponding mean CV score."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 17,
            "metadata": {},
            "outputs": [],
            "source": [
                "for reg_coef in [1e-07,1e-05, 0.001, 0.1, 1, 10, 100, 1000]:\n",
                "    lasso_model = Lasso(alpha=reg_coef)\n",
                "    lasso_CV_scores = cross_val_score(???, ???, ???, cv=5, scoring=rmse)\n",
                "    print(reg_coef, lasso_CV_scores.mean(), sep='\\t')"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Take a look at how the weights of LASSO models change as you change the regularization coefficient!\n",
                "\n",
                "Note: In python, -0 is the same as 0!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Reg coeff. | \", \"Intercept | \", input_cols)\n",
                "print(\"_________________________________________________\")\n",
                "print()\n",
                "\n",
                "for reg_coef in [1e-07,1e-05, 0.001, 0.1, 1, 10, 100, 1000]:\n",
                "    lasso_model = Lasso(alpha=reg_coef)\n",
                "    lasso_model.fit(train_X_norm, train_y)\n",
                "    print(reg_coef, \" | \", lasso_model.intercept_, \" | \",  lasso_model.coef_)\n",
                "    print()"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Discussion:** Do you notice anything interesting about the weights overall? Do you notice anything surprising about the weights of the (first) best performing alpha?"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 5. Computing final test scores"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Using the regularization coefficient that leads to the best validation error, compute test scores for a Ridge and LASSO model."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TODO: choose best alphas from above and calculate test errors\n",
                "print(\"Ridge\", rmse(Ridge(alpha=???).fit(train_X_norm, train_y), test_X_norm, test_y))\n",
                "print(\"LASSO\", rmse(Lasso(alpha=???).fit(train_X_norm, train_y), test_X_norm, test_y))\n",
                "print(\"LinearRegression\", rmse(LinearRegression().fit(train_X_norm, train_y), test_X_norm, test_y))"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now, let's use the same models on the unnormalized training set."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Ridge\", rmse(Ridge(alpha=???).fit(train_X, train_y), test_X, test_y))\n",
                "print(\"LASSO\", rmse(Lasso(alpha=???).fit(train_X, train_y), test_X, test_y))\n",
                "print(\"LinearRegression\", rmse(LinearRegression().fit(train_X, train_y), test_X, test_y))"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Discussion:** So as you can see, the regularized models perform significantly well as opposed to the simple linear models. However, they put too much weight on the 'Phila' county. If we put this model to use in real world, what can be the consequences? Are there any steps we can take to avoid these misinterpretations?\n",
                "\n",
                "**Big Takeaway:** Correlation does not imply causality"
            ]
        }
    ]
}
