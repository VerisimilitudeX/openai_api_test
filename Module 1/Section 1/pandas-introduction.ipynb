{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3 (ipykernel)",
            "language": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 0,
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 1. Setting up"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Import all required modules"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from sklearn.metrics import mean_squared_error\n",
                "from sklearn.linear_model import LinearRegression\n",
                "from sklearn.preprocessing import PolynomialFeatures\n",
                "\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "# Set a fixed random seed to standardize results\n",
                "#np.random.seed(2) # 579"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Read in the weather data and view it. For additional info on the weather dataset we're using, see [this](https://corgis-edu.github.io/corgis/csv/weather/)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TODO: read in weather data and view (hint: only need to view first 5 datapoints)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 2. Pre-processing"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We want to predict the max temperature for a particular week. **What input columns should we use?** (There are multiple reasonable answers.)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "input_cols = [???] #TODO: choose the input columns\n",
                "output_col = 'Data.Temperature.Max Temp'"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Split the weather data into a training and test set and then store the input and target data seperately for each set. Use [train/test split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) from sklearn."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "# TODO: split into training and testing sets\n",
                "train, test = ???\n",
                "\n",
                "# TODO: split data sets into input and target variables\n",
                "train_X = ???\n",
                "train_y = ???\n",
                "\n",
                "test_X = ???\n",
                "test_y = ???"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Check the shape of each set to make sure they make sense!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"train input data shape:\", train_X.shape)\n",
                "print(\"train target data shape:\", train_y.shape)\n",
                "print()\n",
                "print(\"test input data shape:\", test_X.shape)\n",
                "print(\"test target data shape:\", test_y.shape)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 3. Linear regression"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Create a simple [least squares linear Model](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html). "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "####TODO: Define a new linear regression model\n",
                "simple_linear_model = #??? \n",
                "####"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Train the model using the training data and output the training error. To do so, define a function rmse(mode, X, y) that calculates the RMSE error for a given model, input, and target data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "def rmse(model, X, y):\n",
                "    predictions = model.predict(X)\n",
                "    return mean_squared_error(predictions, y, squared=False)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now, let's fit the data to the linear model and then find the error on the training values"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 18,
            "metadata": {},
            "outputs": [],
            "source": [
                "####TODO: Fit simple linear model we just created to training data\n",
                "\n",
                "####\n",
                "\n",
                "#Now taking the Root mean squared error\n",
                "rmse(simple_linear_model, train_X, train_y)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now, let's take a look at what our y-intercept and weights are like in the model we have just created. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(simple_linear_model.intercept_) \n",
                "print(simple_linear_model.coef_)"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Concept check:**  What does this model suggest about useful features? Can you think of a function of important features which is an approximation of what the model is doing?"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 4. Bias - Variance and overfitting"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Let's take a look at the train and test errors we get on the simple model we created. "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Train Error: \", rmse( simple_linear_model, train_X, train_y))\n",
                "print(\"Test Error: \", rmse(simple_linear_model, test_X, test_y))"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "As you can see, the linear model is doing quite well on our data."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now, let's try to train a more complex model using sklearn's PolynomialFeatures which would account for all polynomial combinations of given features to a provided degree. \n",
                "\n",
                "This time, we split the training data into further training set and a **validation set**. Validation is a useful method in checking your model's robustness before actually applying it on test data. If your model is overfitting on the training data, validation set will make us aware of that. We will not be checking the new model on test data in this, but you can do it as an exercise."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 0,
            "metadata": {},
            "outputs": [],
            "source": [
                "train_X, val_X, train_y, val_y = train_test_split(train_X, train_y, test_size=0.1, random_state=1)\n",
                "\n",
                "degrees = [1,2,3,4,5,6]\n",
                "train_errors = []\n",
                "val_errors = []\n",
                "for degree in degrees:\n",
                "    poly_features = PolynomialFeatures(degree) # accont for features of higher degree\n",
                "    poly_train_X = poly_features.fit_transform(train_X)\n",
                "\n",
                "    poly_linear_model = LinearRegression()\n",
                "    poly_linear_model.fit(poly_train_X, train_y)\n",
                "\n",
                "    train_errors.append(rmse(poly_linear_model, poly_train_X, train_y))\n",
                "    val_errors.append(rmse(poly_linear_model, poly_features.transform(val_X) , val_y))\n",
                "\n",
                "# validation vs train error \n",
                "plt.plot(degrees, train_errors, label = \"Train Error\")\n",
                "plt.plot(degrees, val_errors, label = \"Validation Error\")\n",
                "plt.xlabel(\"Degree\")\n",
                "plt.ylabel(\"Errors\")\n",
                "plt.legend()\n",
                "plt.show()\n",
                ""
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**Concept check:** How do the Validation error and Train error compare? Do you see any alarming difference? What might be causing this?"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Now, uncomment the `np.random.seed()` line at the top of the notebook, just below the import statements. Re-run the entire notebook again (use 'Run All' button on top left corner). What do you see? Compare with your neighbors. "
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Introducing np.random.seed() will standardize all the train test splits so you get the same result across different runs. As you can see above after this procedure, the validation error is significantly higher than the train error beginning degree 4, because our model becomes **overfitting** to the dataset provided. "
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**conceptual Question:** Does the linear model have high bias? Does it have high variance?"
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Higher variance is generally co-related with overfitting; high-bias is with underfiting and higher training loss. A complex model which has high complexity to minimize the training error has a tendency to overfit to the training dataset and will might do poorly with the testing dataset."
            ]
        },
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "\n",
                "---\n",
                "\n",
                ""
            ]
        }
    ]
}
